{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Векторная модель текста и классификация длинных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем формулу кросс-энтропии для бинарной классификации. Для единственного примера она вычисляется следующим образом:\n",
    "\n",
    "$$BCE(\\hat{y}, y) = −y\\log(\\hat{y}) − (1−y)\\log(1−\\hat{y})$$\n",
    "\n",
    "где y∈{0,1} - настоящая метка класса для объекта, а $ 0 < \\hat{y} < 1 $ - вероятность класса 1, предсказанная моделью.\n",
    "\n",
    "В процессе обучения классификатора мы минимизируем кросс-энтропию на всех обучающих примерах (сравните с описанием BCELoss в PyTorch):\n",
    "\n",
    "$$ BCE_{1..n} = \\sum_{i=1}^{n}−y_i\t\\log(\\hat{y}_i) − (1−y_i)\\log(1− \\hat{y}_i) → min $$\n",
    "\n",
    "Например, на двух обучающих примерах  \n",
    "\n",
    "$y_1=1, y_2=1$ формула примет вид:\n",
    "\n",
    "$$ BCE_{1,2}=−\\log(\\hat{y}_1) −\\log(\\hat{y}_2) $$\n",
    "\n",
    "Мы предлагаем вам проанализировать полученную формулу на следующих предсказаниях модели \n",
    "\t\n",
    "$\\hat{y}_1, \\hat{y}_2 = [0.99,0.01]$ - первый объект классифицируется уверенно правильно, а второй уверенно неправильно\n",
    "\n",
    "$\\hat{y}_1, \\hat{y}_2 = [0.5,0.5]$ - модель не может принять решения, абсолютно неуверенное предсказание\t\n",
    "\n",
    "$\\hat{y}_1, \\hat{y}_2 = [0.99,0.45]$ - первый объект классифицируется уверенно правильно, а второй неуверенно неправильно\n",
    "\n",
    "$\\hat{y}_1, \\hat{y}_2 = [0.65,0.65]$ - оба объекта классифицируются правильно, но классификатор не очень уверен в принятом решении\n",
    "\n",
    "Какие виды ошибок с точки зрения кросс-энтропии более критичны и насколько это согласуется с Вашими ожиданиями как человека? :)\n",
    "\n",
    "Фраза \"Модели выгоднее предсказывать А, чем Б\" означает, что суммарое значение функции потерь будет ниже, если модель предскажет набор ответов А, по сравнению с ситуацией, в которой она для тех же объектов предскажет набор ответов Б."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(y1, y2):\n",
    "    return -np.log(y1) - np.log(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [(0.99, 0.01), (0.5, 0.5), (0.99, 0.45), (0.65, 0.65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.615220521841592\n",
      "1.3862943611198906\n",
      "0.8085580320712731\n",
      "0.8615658321849085\n"
     ]
    }
   ],
   "source": [
    "for value in values:\n",
    "    print(f(*value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы обучаете одномерную логистическую регрессию \n",
    "\n",
    "$\\hat{y}(x)= \\frac{1}{1+e^{−wx−b}} $, то есть\n",
    "w∈R - это скаляр (число).\n",
    "\n",
    "x - единственный признак входного объекта,\n",
    "\n",
    "y(x)∈{0,1} - настоящий класс объекта x,  \n",
    "\n",
    "$ 0 < \\hat{y} (x) < 1 $ - предсказанная вероятность того, что x принадлежит к классу 1.\n",
    "\n",
    "В качестве функции потерь Вы используете бинарную кросс-энтропию \n",
    "\n",
    "$$BCE(\\hat{y}, y) = −y\\log(\\hat{y}) − (1−y)\\log(1−\\hat{y})$$\n",
    "\n",
    "Найдите в общем виде производную функции потерь $BCE(\\hat{y}, y)$ по w и запишите в ответ её формулу. Для обозначений используйте латинские буквы y, x, w, b в нижнем регистре.\n",
    "\n",
    "Ответ должен компилироваться в Sympy. Вам могут понадобиться операции деления /, умножения *, сложения +, вычитания - и взятия экспоненты  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Downloading sympy-1.6.2-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 770 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.1.0.tar.gz (512 kB)\n",
      "\u001b[K     |████████████████████████████████| 512 kB 13.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: mpmath\n",
      "  Building wheel for mpmath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpmath: filename=mpmath-1.1.0-py3-none-any.whl size=532239 sha256=982201873083fc0be43bbaeefb9f29de9279cf1ec89e4e4818687fd6e090f3ca\n",
      "  Stored in directory: /Users/anastasiabogatenkova/Library/Caches/pip/wheels/e2/46/78/e78f76c356bca9277368f1f97a31b37a8cb937176d9511af31\n",
      "Successfully built mpmath\n",
      "Installing collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.1.0 sympy-1.6.2\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/Users/anastasiabogatenkova/miniconda3/envs/sphere/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0237129365887834\n"
     ]
    }
   ],
   "source": [
    "from sympy.parsing import sympy_parser\n",
    "\n",
    "sample_expr_str = 'x * (- exp(- x * w - b) * y + (1 - y)) / (1 + exp(- x * w - b))'\n",
    "sample_expr = sympy.parsing.sympy_parser.parse_expr(sample_expr_str)\n",
    "sample_value = sample_expr.evalf(subs=dict(x=0.5, y=1, w=4, b=1))\n",
    "print(sample_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдите в общем виде производную функции потерь $BCE(\\hat{y}, y)$ по b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0474258731775668\n"
     ]
    }
   ],
   "source": [
    "import sympy.parsing.sympy_parser\n",
    "\n",
    "sample_expr_str = '(- exp(- x * w - b) * y + (1 - y)) / (1 + exp(- x * w - b))'\n",
    "sample_expr = sympy.parsing.sympy_parser.parse_expr(sample_expr_str)\n",
    "sample_value = sample_expr.evalf(subs=dict(x=0.5, y=1, w=4, b=1))\n",
    "print(sample_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте L2-регуляризацию \n",
    "\n",
    "$$ Loss(\\hat{y}, y) = BCE(\\hat{y}, y) + c(w^2+b^2) $$\n",
    "где c > 0 - коэффициент регуляризации.\n",
    "\n",
    "Найдите в общем виде производную функции $ Loss(\\hat{y}, y) $ по w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.97628706341122\n"
     ]
    }
   ],
   "source": [
    "import sympy.parsing.sympy_parser\n",
    "\n",
    "sample_expr_str = 'x * (- exp(- x * w - b) * y + (1 - y)) / (1 + exp(- x * w - b)) + 2 * c * w'\n",
    "sample_expr = sympy.parsing.sympy_parser.parse_expr(sample_expr_str)\n",
    "sample_value = sample_expr.evalf(subs=dict(x=0.5, y=1, w=4, b=1, c=1))\n",
    "print(sample_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя формулу производной с предыдущего шага, запишите формулу для обновления веса w с помощью стохастического градиентного спуска (размер минибатча равен 1). Для обозначения скорости обучения (learning rate) используйте маленькую латинскую букву t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w - t * ( x * (- exp(- x * w - b) * y + (1 - y)) / (1 + exp(- x * w - b)) + 2 * c * w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы предлагаем Вам поразмышлять над разницей в мощности двух вариантов логистической регрессии:\n",
    "\n",
    "$ \\hat{y_1}(x) = σ(wx+b) $\n",
    "\n",
    "$ \\hat{y_2}(x) = σ(wx+b) $, где b=0\n",
    "\n",
    "Выберите варианты ответа (один или несколько), соответствующие датасетам, которые могут быть успешно обработаны \n",
    "$ \\hat{y_1}(x) $ и не могут быть обработаны $ \\hat{y_2}(x) $.\n",
    "\n",
    "<img src=\"images/bias.png\" width=400/>\n",
    "\n",
    "2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию для вычисления точечной взаимной информации двух случайных событий.\n",
    "\n",
    "$$ pmi(a,b)= \\log \\frac{p(a)p(b)}{p(a,b)} $$\n",
    "\n",
    "На вход функция получает два массива из 0 и 1 одинаковой длины - реализации случайных событий. 1 - событие произошло, 0 - не произошло.\n",
    "\n",
    "В результате функция должна вернуть вещественное число - точечную взаимную информацию событий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.693147\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array([int(s.strip()) for s in s.strip().split(' ')])\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def calculate_pmi(a, b):\n",
    "    #p(w,l) = число_событий(и там и там единица)/длина(w)\n",
    "    # p(w) = число_событий(единица в w)/длина(w)\n",
    "    # p(l) = число_событий(единица в l)/длина(l)\n",
    "    # длина(w) == длина(l)\n",
    "    p_a_b = np.sum((a == b) & (a == 1)) / a.shape[0]\n",
    "    p_a = np.sum(a) / a.shape[0]\n",
    "    p_b = np.sum(b) / b.shape[0]\n",
    "    return np.log(p_a_b / (p_a * p_b))\n",
    "\n",
    "a = np.array([1, 0, 0, 1, 1, 0])\n",
    "b = np.array([1, 0, 0, 0, 1, 0])\n",
    "pmi_value = calculate_pmi(a, b)\n",
    "\n",
    "print('{:.6f}'.format(pmi_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите количество слов, которые встречаются менее, чем в 10 из 10000 документов, если предполагать, что вероятность встретить слово в документе распределена по Ципфу с параметром s=2, количество слов в словаре N=1000. Ранги нумеруются с 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sum([1 / x ** 2 for x in range(1,1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.663679512615907"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000 / z) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 - 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Базовые нейросетевые методы работы с текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
